{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity\n",
    "\n",
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lib.database_module as db\n",
    "import lib.encoding_module as en\n",
    "import lib.download_mine as down\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import unidecode\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Cosine Similarity, based on the full text of the category.\n",
    "\n",
    "`category_text` is results of a SQL query to return a category_id and the text all pages in that category.  The results are split into a training and test set.  The training set is merged into a single category vector.  The test set is left as individual pages.  The training sets are used to generate a vectorizor and the vectors of each category are returned for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "category_text = db.fetch_all_category_pages('local')\n",
    "\n",
    "train_text, test_text = train_test_split(category_text,test_size = .15)\n",
    "\n",
    "cate_train_dict = {}\n",
    "for p in train_text:\n",
    "    cate_train_dict[p[0]] = cate_train_dict.get(p[0],p[1])+ ' '+p[1]   \n",
    "\n",
    "cate_text_dict = {}\n",
    "for k, text in tqdm.tqdm_notebook(cate_train_dict.items()):\n",
    "    cate_text_dict[k] = en.clean_page_text(text)\n",
    "\n",
    "categories, texts = zip(*cate_text_dict.items())\n",
    "\n",
    "cat_vectorizer, cat_vectors = en.build_vectorizer(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4029"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cos_similarity_compare(page_vector, cate_vectors, category_list):\n",
    "    cos = cosine_similarity(cate_vectors,page_vector)\n",
    "    best = cos.argmax()\n",
    "    match1 = category_list[best]\n",
    "    cos = np.delete(cos,best)\n",
    "    category_list = np.delete(category_list,best)\n",
    "    penultimate = cos.argmax()\n",
    "    match2 = category_list[penultimate]\n",
    "    return match1, match2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_cos_similarity(cate_text_list, vectorizer, category_vectors, categories):\n",
    "    temp_categories= []\n",
    "    temp_texts=[]\n",
    "    temp_results = []\n",
    "    for category, text in tqdm.tqdm_notebook(cate_text_list):\n",
    "        temp_categories.append(category)\n",
    "        temp_texts.append(en.clean_page_text(text))\n",
    "\n",
    "    text_vectors = vectorizer.transform(temp_texts)\n",
    "    \n",
    "    test_vectors = zip (temp_categories, text_vectors)\n",
    "\n",
    "    for t in tqdm.tqdm_notebook(test_vectors):\n",
    "        pred, pred2 = cos_similarity_compare(t[1].reshape(1,-1),\n",
    "                                      category_vectors,\n",
    "                                      np.array(categories))\n",
    "        actual = t[0]\n",
    "\n",
    "    #    print actual, pred, pred2\n",
    "        if pred == actual:# or pred2 == actual: #Include 2 best matches\n",
    "            temp_results.append(int(1))\n",
    "        else:\n",
    "            temp_results.append(int(0))\n",
    "\n",
    "    accuracy = float(sum(temp_results))/len(cate_text_list)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Score\n",
      "\n",
      " Accuracy: 94.12%\n",
      "None\n",
      "Test Score\n",
      "\n",
      " Accuracy: 92.28%\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print \"train Score\", test_cos_similarity(train_text,cat_vectorizer,cat_vectors,categories)\n",
    "print \"Test Score\", test_cos_similarity(test_text,cat_vectorizer,cat_vectors,categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Subcategories_dict = {'Sandwiches':'American sandwiches',\n",
    "                'desserts':'cookies',\n",
    "                'chemistry':'Industrial gases',\n",
    "                'physics':'physicists',\n",
    "                'sports cars': 'muscle cars',\n",
    "                'psychology':'Popular psychology',\n",
    "                'Arcade games':'Cancelled arcade games',\n",
    "                'machine learning':'Classification algorithms',\n",
    "                'cat breeds':'Natural cat breeds',\n",
    "                'Earth sciences':'Geochemistry',\n",
    "                'Breads':'Bread dishes',\n",
    "                'Automotive technologies':'Vehicle dynamics',\n",
    "                'belief':'Ignorance',\n",
    "                'hygiene':'Ritual purification',\n",
    "                'sports terminology':'martial arts terminology',\n",
    "                'shoes':'Sneaker culture',\n",
    "                'influenza':'Influenza researchers',\n",
    "                'Children':'Sons of Odin',\n",
    "                'physical quantities':'Density',\n",
    "                'Physical exercise':'hydrotherapy',\n",
    "                'health care':'medical robotics'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Subcategory_number_dict = {}\n",
    "\n",
    "for k,v in tqdm.tqdm_notebook(Subcategories_dict.items()):\n",
    "    parent = down.wikipedia_get_page(k, category=True)\n",
    "    child =  down.wikipedia_get_page(v, category=True)\n",
    "    Subcategory_number_dict[v] ={'parent_name':k,\n",
    "                                 'parent_id':int(parent.keys()[0]) , \n",
    "                                 'category_id': int(child.keys()[0]),\n",
    "                                 'pages' :{p['pageid']: down.get_text(p['pageid']) \n",
    "                                           for p in down.wikipedia_get_pages_for_category(v) \n",
    "                                           if p['ns'] == 0}}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score\n",
      "\n",
      " Accuracy: 72.31%\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# down.get_text(k)\n",
    "validation_text_list = []\n",
    "for k, v in Subcategory_number_dict.items():\n",
    "    for key,text in v['pages'].items():\n",
    "        validation_text_list.append([v['parent_id'], en.clean_page_text(text)])\n",
    "print \"Validation Score\", test_cos_similarity(validation_text_list,cat_vectorizer,cat_vectors,categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_text_list[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_temp = [en.clean_page_text(t[1]) for t in tqdm.tqdm_notebook(train_text)]\n",
    "y_train_tf = [t[0] for t in tqdm.tqdm_notebook(train_text)]\n",
    "X_test_temp = [en.clean_page_text(t[1]) for t in tqdm.tqdm_notebook(test_text)]\n",
    "y_test_tf = [t[0] for t in tqdm.tqdm_notebook(test_text)]\n",
    "X_val_temp = [en.clean_page_text(t[1]) for t in tqdm.tqdm_notebook(validation_text_list)]\n",
    "y_val_tf = [t[0] for t in tqdm.tqdm_notebook(validation_text_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer, X_tf_train = en.build_tfidf_vectorizer(X_train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tf_test = vectorizer.transform(X_test_temp)\n",
    "X_tf_validation = vectorizer.transform(X_val_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(vectorizer.get_feature_names())\n",
    "\n",
    "131072/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.neural_network as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlpc = nn.MLPClassifier(verbose =3, \n",
    "                        max_iter=2000, \n",
    "                        activation = 'logistic',\n",
    "                        solver='adam',\n",
    "                        hidden_layer_sizes=(131072,256) ,\n",
    "                        tol=.001)\n",
    "                    \n",
    "mlpc.fit(X_tf_train, y_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlpc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5d3b9618b386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Training Set Accuracy: {:.1%}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_tf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Testing Set Accuracy: {:.1%}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tf_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_tf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Validation Set Accuracy: {:.1%}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tf_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val_tf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mlpc' is not defined"
     ]
    }
   ],
   "source": [
    "print \"Training Set Accuracy: {:.1%}\".format(mlpc.score(X_tf_train,y_train_tf))\n",
    "print \"Testing Set Accuracy: {:.1%}\".format(mlpc.score(X_tf_test,y_test_tf))\n",
    "print \"Validation Set Accuracy: {:.1%}\".format(mlpc.score(X_tf_validation,y_val_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {
    "08c2af2688e64b558e0514ae4a6c75c1": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "0d0e893a377449aebe875479a7f8f67d": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "4b7d3f6eba9f4122aeba850503584110": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "5381cfdbf2fd4b808af7865d208f34d7": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "595ba19afb484106a2e982914a1fa5e5": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "814174d9954a4742ae6af6963e34b9a6": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "9ab719c3898a46779a88cb1fd00ffa3c": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "b269733a4e0b444190fb9da99dd8c40f": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "b364caa93bb4463999c093c745df4c47": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "bddd076e4cea423d8f4d6f397f58a821": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "ce5f239b2d8b4f34aefffbe9e4c79cb1": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "d07d38e292f8433592de1499f5890191": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "d0cd23e8e00147dfb2e88789e3becc79": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "d9594896455a487a9786334944efb342": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
